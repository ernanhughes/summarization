{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "def summarize(text, language=\"english\", sentences_count=5):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return ' '.join([str(sentence) for sentence in summary])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download nltk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk \n",
    "os.system(\"python3 -m nltk.downloader punkt\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your sample text goes here. Replace this text with the content you want to summarize.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Your sample text goes here. Replace this text with the content you want to summarize.\"\"\"\n",
    "summary = summarize(text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic summarization is the process of shortening a set of data computationally, to create a subset (a summary) that represents the most important or relevant information within the original content.\n",
      "Some techniques and algorithms which naturally model summarization problems are TextRank and PageRank, Submodular set function, Determinantal point process, maximal marginal relevance (MMR) etc.\n",
      "\"The Army Corps of Engineers, rushing to meet President Bush's promise to protect New Orleans by the start of the 2006 hurricane season, installed defective flood-control pumps last year despite warnings from its own expert that the equipment would fail during a storm, according to documents obtained by The Associated Press\".\n",
      "Although the system exhibited good results, the researchers wanted to explore the effectiveness of a maximum entropy(ME) classifier for the meeting summarization task, as ME is known to be robust against feature dependencies.\n",
      "Automatic summaries present information extracted from multiple sources algorithmically, without any editorial touch or subjective human intervention, thus making it completely unbiased.\n",
      "ISBN 978-1-848-21668-6.^ Pan, Xingjia; Tang, Fan; Dong, Weiming; Ma, Chongyang; Meng, Yiping; Huang, Feiyue; Lee, Tong-Yee; Xu, Changsheng (2021-04-01).\n",
      "S2CID 7007323.^ Rada Mihalcea and Paul Tarau, 2004: TextRank: Bringing Order into Texts, Department of Computer Science University of North Texas\"Archived copy\"(PDF).\n",
      "S2CID 7853204.^ Sebastian Tschiatschek, Rishabh Iyer, Hoachen Wei and Jeff Bilmes, Learning Mixtures of Submodular Functions for Image Collection Summarization, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.\n",
      "216–217., Published in Proceeding RIAO'10 Adaptivity, Personalization and Fusion of Heterogeneous Information, CID Paris, France Xiaojin, Zhu, Andrew Goldberg, Jurgen Van Gael, and David Andrzejewski (2007).\n",
      "{{ cite book}}: CS1 maint: multiple names: authors list ( link), The GRASSHOPPER algorithm Miranda-Jiménez, Sabino, Gelbukh, Alexander, and Sidorov, Grigori (2013).\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 10\n",
    "\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Automatic_summarization\"\n",
    "parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "# or for plain text files\n",
    "# parser = PlaintextParser.from_file(\"document.txt\", Tokenizer(LANGUAGE))\n",
    "# parser = PlaintextParser.from_string(\"Check this out.\", Tokenizer(LANGUAGE))\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "summarizer = Summarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LuhnSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "sentences_count = 2\n",
    "summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2, bonus_words=None, stigma_words=None, null_words=None):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = EdmundsonSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    if bonus_words:\n",
    "        summarizer.bonus_words = bonus_words\n",
    "    if stigma_words:\n",
    "        summarizer.stigma_words = stigma_words\n",
    "    if null_words:\n",
    "        summarizer.null_words = null_words\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "sentences_count = 2\n",
    "bonus_words = [\"intelligence\", \"AI\"]\n",
    "stigma_words = [\"contrast\"]\n",
    "null_words = [\"the\", \"of\", \"and\", \"to\", \"in\"]\n",
    "\n",
    "summary = summarize_paragraph(paragraph, sentences_count, bonus_words, stigma_words, null_words)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ernan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LsaSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "sentences_count = 2\n",
    "summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
